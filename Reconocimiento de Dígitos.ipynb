{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versión de tensorflow: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"versión de tensorflow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos de entrenamiento: 55000\n",
      "Número de ejemplos de validación: 5000\n",
      "Número de ejemplos de prueba: 10000\n",
      "Tamaño de cada dígito: 784\n",
      "Tamaño de cada etiqueta: 10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "### Los Ejemplos de entrenamiento están en: \n",
    "# mnist.train.images\n",
    "print(\"Número de ejemplos de entrenamiento:\", mnist.train.images.shape[0])\n",
    "\n",
    "### El conjunto de validacion es: \n",
    "# mnist.validation\n",
    "print(\"Número de ejemplos de validación:\", mnist.validation.images.shape[0])\n",
    "\n",
    "\n",
    "### El conjunto de prueba es: \n",
    "# mnist.test\n",
    "print(\"Número de ejemplos de prueba:\", mnist.test.images.shape[0])\n",
    "\n",
    "\n",
    "### Cada dígito es un vector de dimensión 784 .\n",
    "print(\"Tamaño de cada dígito:\", mnist.train.images.shape[1])\n",
    "\n",
    "\n",
    "### Las etiquetas se encuentran en: \n",
    "# mnist.train.labels\n",
    "# mnist.validation.labels\n",
    "# mnist.test.labels\n",
    "\n",
    "print(\"Tamaño de cada etiqueta:\", mnist.train.labels.shape[1])\n",
    "#Cada etiqueta es un one-hot-vector,ie. un vector con un solo uno, las demás entradas son cero\n",
    "#[1,0,0,0,0,0,0,0,0,0]  representa el número 0\n",
    "#[0,1,0,0,0,0,0,0,0,0]  representa el número 1\n",
    "#   .\n",
    "#   .\n",
    "#   .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra Dígito "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada dígito se almacena como un vector de 784 dimensiones. Para visualizarlo, primero lo redimensionamos a una imagen de 28x28.\n",
    "def muestra_digito(x):\n",
    "    \"\"\"\n",
    "        x: vector \n",
    "            784 dimensiones\n",
    "        Muestra el vector como una imágen de 28x28\n",
    "    \"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def vis_imagen(i, conjunto=\"train\"):\n",
    "    \"\"\"\n",
    "        i indice del conjunto especificado\n",
    "        conjunto: cadena\n",
    "            Cualquiera: train, validation, test\n",
    "            \n",
    "        Muestra el dígito en el indice i  y su etiqueta\n",
    "    \"\"\"\n",
    "    if(conjunto==\"train\"): \n",
    "        muestra_digito(mnist.train.images[i,])\n",
    "        label = np.argwhere(mnist.train.labels[i])[0][0]\n",
    "    elif(conjunto==\"test\"): \n",
    "        muestra_digito(mnist.test.images[i,])\n",
    "        label = np.argwhere(mnist.test.labels[i])[0][0]\n",
    "    else:\n",
    "        muestra_digito(mnist.validation.images[i,])\n",
    "        label = np.argwhere(mnist.validation.labels[i])[0][0]\n",
    "    print(\"Etiqueta \" + str(label))\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b95f72978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b97fcb0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b95f98208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b9801ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "vis_imagen(0, conjunto=\"train\")\n",
    "vis_imagen(132, conjunto=\"validation\")\n",
    "vis_imagen(32, conjunto=\"test\")\n",
    "vis_imagen(50000, conjunto=\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders para los datos de entrenamiento\n",
    "### En ellos se pasaran despues los datos de entrenamiento (x,y)\n",
    "### x imagen, y etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784]) \n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capa 1\n",
    "W_1 = tf.Variable(tf.truncated_normal(shape = [784,512], stddev=0.2))\n",
    "b_1 = tf.Variable(tf.zeros([512]))\n",
    "\n",
    "### Capa 2 de salida\n",
    "W_2 = tf.Variable(tf.truncated_normal(shape = [512,10], stddev=0.2))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura de la red neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x):\n",
    "    \"\"\"\n",
    "        x: matriz\n",
    "            su forma  debe ser (m, 784)\n",
    "            \n",
    "        regresa la activación de la capa de salida\n",
    "        matriz de (m, 10)\n",
    "    \"\"\"\n",
    "    # Capa Escondida 1. \n",
    "    z_1 = tf.matmul(x,W_1) + b_1 ### Combinación lineal\n",
    "    a_1  = tf.nn.relu(z_1)     ### Activación (función no lineal)\n",
    "    \n",
    "    # Capa 2. Está es la capa de salida\n",
    "    z_2 = tf.matmul(a_1,W_2) + b_2 ### Combinación lineal\n",
    "    \n",
    "    return z_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = NN(x)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = tf.nn.softmax(y_) # predicciones en el conjunto de entrenamiento\n",
    "### Nota: la función softmax calcula la probabilidad de cada etiqueta del 0 al 9.\n",
    "#Para obtener la predicción necesitamos usar las función tf.argmax(y_,1) o su versión en python np.argmax(y_,1)\n",
    "#Así se elige el dígito más probable para la imágen\n",
    "#Esto lo hace la función precision\n",
    "\n",
    "y_valid = NN(mnist.validation.images)\n",
    "valid_pred = tf.nn.softmax(y_valid) # predicciones en el conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesión e inicializacion de varables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session() #Crea una sessión\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precisión\n",
    "def precision(predicciones, etiquetas):\n",
    "    return (100.0 * np.sum(np.argmax(predicciones, 1) == np.argmax(etiquetas, 1))\n",
    "          / predicciones.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "Costo del minibatch hasta el paso 0: 0.001599\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 500: 0.001761\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1000: 0.000944\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1500: 0.002883\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2000: 0.002234\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2500: 0.000586\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3000: 0.001645\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3500: 0.000941\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4000: 0.001073\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4500: 0.001149\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pasos = 5000\n",
    "\n",
    "print(\"Entrenamiento:\")\n",
    "for i in range(pasos):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _,costo,predicciones =  sess.run([opt, cross_entropy, train_pred],  feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "        print(\"Costo del minibatch hasta el paso %d: %f\" % (i, costo))\n",
    "        print(\"Precisión en el conjunto de entrenamiento: %.1f%%\" % precision(predicciones, batch[1]))\n",
    "        print(\"Precision en el conjunto de validación: %.1f%%\" % precision(\n",
    "        valid_pred.eval(session=sess), mnist.validation.labels))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de PRUEBA: 98.0%\n"
     ]
    }
   ],
   "source": [
    "y_test = NN(mnist.test.images)\n",
    "test_prediction = tf.nn.softmax(y_test)\n",
    "print(\"Precisión en el conjunto de PRUEBA: %.1f%%\" % precision(test_prediction.eval(session = sess), mnist.test.labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABQdJREFUeJzt3C+L1FsAx+Gdy30JKwgWg0E22WRRk2Aw2ixishsMJsE3oF3FYLCIwSRs0XdgtAj+Abe4Bi2yIL/7Cvaw7oyzc+fzPPXr7J7y4YTj7Gyapg2g55/jPgBwPMQPUeKHKPFDlPghSvwQJX6IEj9EiR+i/l3mL5vNZv47Ifxl0zTNDvPv3PwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6h/j/sA/F1nzpwZ7k+fPh3u9+/fH+47Ozt/fCZWg5sfosQPUeKHKPFDlPghSvwQJX6I8s6/5u7duzfcL168ONxv3Lgx3N++fTvc9/f3hzvHx80PUeKHKPFDlPghSvwQJX6I8tS35s6dOzfcp2ka7tvb28N9a2truL979264c3zc/BAlfogSP0SJH6LED1HihyjxQ5R3/rjv378P92fPng33L1++LPI4LJGbH6LED1HihyjxQ5T4IUr8ECV+iPLOH7e7uzvcf/z4Mdz39vYWeRyWyM0PUeKHKPFDlPghSvwQJX6IEj9Eeedfc48fPx7uDx48GO4nT55c5HFYIW5+iBI/RIkfosQPUeKHKPFDlPghyjv/mtvc3Jzr81+/fl3QSVg1bn6IEj9EiR+ixA9R4oco8UOUp741t7+/P9fnf/36taCTsGrc/BAlfogSP0SJH6LED1HihyjxQ5R3/jU37zv/8+fPF3QSVo2bH6LED1HihyjxQ5T4IUr8ECV+iPLOvwbOnj174Hb9+vW5fvb58+eH+87Ozlw/n+Pj5oco8UOU+CFK/BAlfogSP0SJH6K886+B9+/fH7hdvnx5+Nnd3d3hvrW1Ndy98/9/ufkhSvwQJX6IEj9EiR+ixA9R4oco7/xrbm9vb7i/fv16SSdh1bj5IUr8ECV+iBI/RIkfosQPUbNpmpb3y2az5f0yDuXVq1fD/cSJE8N9e3t7kcdhAaZpmh3m37n5IUr8ECV+iBI/RIkfosQPUeKHKF/pjfv9+/dwP3Xq1HDf3Nwc7t++ffvjM7Ecbn6IEj9EiR+ixA9R4oco8UOU+CHK9/njLly4MNzfvHkz3O/cuTPcHz58+KdHYk6+zw8MiR+ixA9R4oco8UOU+CFK/BDlnZ+hz58/D/dPnz4N90uXLi3yOByCd35gSPwQJX6IEj9EiR+ixA9R/nQ3Qy9fvhzut27dGu6nT58+cPv48eMRTsSiuPkhSvwQJX6IEj9EiR+ixA9R4ocoX+ll6MqVK8P9xYsXw/3JkycHbrdv3z7SmRjzlV5gSPwQJX6IEj9EiR+ixA9R4oco7/zM5e7du8P95s2bB25Xr14dfvbDhw9HOVKed35gSPwQJX6IEj9EiR+ixA9R4oco7/zMZfR3+Tc2NjYePXp04Pbz58/hZ69du3aUI+V55weGxA9R4oco8UOU+CFK/BAlfojyzg9rxjs/MCR+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6il/uluYHW4+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oeo/wA8prM0gyJkFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20bab694c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "indice = 251\n",
    "p = tf.argmax(NN(mnist.test.images[indice:indice+1]).eval(session = sess),1)\n",
    "print(\"Predicción:\", sess.run(p)[0])\n",
    "vis_imagen(indice, conjunto=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    # Only process if image has transparency \n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL \n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usa tu propia imágen\n",
    "\n",
    "### Cambia el nombre de de la variabel imagen por la tuya.\n",
    "#### La imágen debe se una imágen cuadrada y cada dimensión mayor a 28.\n",
    "#### Ej. una  imágen de (512,512) en formato png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágen:numero8.png\n",
      "Predicción: 8\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "imagen = \"numero8.png\"\n",
    "img = Image.open(imagen)\n",
    "img = remove_transparency(img).convert('L')\n",
    "\n",
    "if  img.size != (28,28):\n",
    "    img.thumbnail((28,28), Image.ANTIALIAS)\n",
    "\n",
    "entrada = np.array(img, dtype = np.float32)\n",
    "entrada = entrada.reshape((1,784))\n",
    "entrada = entrada/255.0\n",
    "        \n",
    "p = tf.argmax(NN(entrada).eval(session = sess),1)\n",
    "print(\"Imágen:{}\".format(imagen))\n",
    "img.show()\n",
    "print(\"Predicción:\", sess.run(p)[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
